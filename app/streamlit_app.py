# app/streamlit_app.py

import streamlit as st
import pandas as pd
import joblib
import json
import os
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image

# ===============================
# Load model metadata
# ===============================
metadata_path = "../models/model_metadata.json"
os.makedirs("../models", exist_ok=True)

if not os.path.exists(metadata_path):
    metadata = {"current_version": 1, "versions": {}}
    with open(metadata_path, "w") as f:
        json.dump(metadata, f, indent=4)
else:
    with open(metadata_path, "r") as f:
        metadata = json.load(f)

v = metadata.get("current_version", 1)

# ===============================
# Load current model + tools
# ===============================
model = joblib.load(f"../models/trained_model_v{v}.pkl")
scaler = joblib.load(f"../models/scaler_v{v}.pkl")
le = joblib.load(f"../models/label_encoder_v{v}.pkl")
FEATURES = joblib.load("../models/feature_list.pkl")

# ===============================
# Streamlit UI setup
# ===============================
st.set_page_config(page_title="ğŸª Kepler Exoplanet Classifier", layout="wide")
st.title("ğŸª Kepler Exoplanet Classifier")

st.markdown(f"""
### Current Model Version: **v{v}**
This AI model classifies potential **exoplanet detections** as:
- ğŸŸ¢ **CONFIRMED EXOPLANET** â€” Definitely a planet 
- ğŸŸ¡ **PLANETARY CANDIDATE** â€” Likely a planet, not yet confirmed 
- ğŸ”´ **FALSE POSITIVE** â€” Probably not a planet due to various
""")

# ===============================
# Feature Importance
# ===============================
st.subheader("ğŸŒŸ Top Features Influencing Planet Detection")
feature_plot_path = f"../models/feature_importances_v{v}.png"

if os.path.exists(feature_plot_path):
    st.image(feature_plot_path, caption=f"Feature Importance (Model v{v})", width=800)
else:
    st.warning("âš ï¸ Feature importance plot not found. Please train or retrain the model first.")

# ===============================
# ğŸ“‚ Option 1: Upload file for prediction
# ===============================
st.header("ğŸ“‚ Predict Using Uploaded Data")
uploaded_file = st.file_uploader("Upload a CSV file with Kepler features", type=["csv"])

if uploaded_file:
    new_data = pd.read_csv(uploaded_file)
    st.write("âœ… Uploaded Data Preview:", new_data.head())

    try:
        new_data = new_data[FEATURES]
        new_data = new_data.fillna(new_data.median())
        new_data_scaled = scaler.transform(new_data)
        predictions = model.predict(new_data_scaled)
        predicted_labels = le.inverse_transform(predictions)

        new_data["Predicted Class"] = predicted_labels
        st.subheader("ğŸ§® Predictions")
        st.dataframe(new_data.head())

        csv = new_data.to_csv(index=False).encode("utf-8")
        st.download_button("â¬‡ï¸ Download Predictions", csv, "exoplanet_predictions.csv", "text/csv")
    except Exception as e:
        st.error(f"âŒ Error during prediction: {e}")

# ===============================
# ğŸ”­ Option 2: Manual Input
# ===============================
st.header("ğŸ”­ Predict Using Manual Input")

with st.form("manual_input_form"):
    st.subheader("Observational Parameters")

    col1, col2 = st.columns(2)
    with col1:
        koi_period = st.number_input("Orbital Period (days)", 0.0, 500.0, 45.3)
        koi_depth = st.number_input("Transit Depth (ppm)", 0.0, 20000.0, 1200.0)
        koi_prad = st.number_input("Planetary Radius (Earth radii)", 0.0, 20.0, 1.2)
        koi_eqtemp = st.number_input("Equilibrium Temperature (K)", 0.0, 3000.0, 580.0)
    with col2:
        koi_stefftemp = st.number_input("Stellar Temperature (K)", 3000.0, 10000.0, 5500.0)
        koi_srad = st.number_input("Stellar Radius (solar radii)", 0.0, 10.0, 0.9)
        koi_slogg = st.number_input("Stellar Surface Gravity (log10(cm/sÂ²))", 0.0, 6.0, 4.4)
        koi_kepmag = st.number_input("Kepler-band Magnitude", 0.0, 20.0, 13.2)

    st.markdown("---")

    st.warning("""
     **Note:** Features like `disposition_score`, `Centroid Offset Flag`, `Stellar Eclipse Flag`, `Not Transit-Like Flag`, and `Ephemeris Match Indicates Contamination Flag` are **system-generated by NASAâ€™s pipeline**.
    Best left unchanged unless you're a space scientist validating data. They are listed under "Advanced Mode" below.
    """)

    with st.expander("âš™ï¸ Advanced (System Features)"):
        disposition_score = st.slider("Disposition Score (0â€“1)", 0.0, 1.0, 0.5)
        ntl_fpflag = st.selectbox("Not Transit-Like Flag", [0, 1], index=0)
        se_fpflag = st.selectbox("Stellar Eclipse Flag", [0, 1], index=0)
        co_fpflag = st.selectbox("Centroid Offset Flag", [0, 1], index=0)
        ec_fpflag = st.selectbox("Ephemeris Contamination Flag", [0, 1], index=0)

    submitted = st.form_submit_button("ğŸš€ Classify Object")

if submitted:
    try:
        input_data = pd.DataFrame([[
            disposition_score, ntl_fpflag, se_fpflag, co_fpflag, ec_fpflag,
            koi_period, koi_depth, koi_prad, koi_eqtemp,
            koi_stefftemp, koi_srad, koi_slogg, koi_kepmag
        ]], columns=FEATURES)

        input_scaled = scaler.transform(input_data)
        pred = model.predict(input_scaled)
        label = le.inverse_transform(pred)[0]

        color_map = {
            "CONFIRMED": "ğŸŸ¢",
            "CANDIDATE": "ğŸŸ¡",
            "FALSE POSITIVE": "ğŸ”´"
        }
        st.success(f"{color_map.get(label.upper(), 'âœ¨')} Predicted Class: **{label}**")
    except Exception as e:
        st.error(f"âŒ Error in classification: {e}")

# ===============================
# ğŸ§  Retrain and Version Model
# ===============================
st.header("ğŸ§  Retrain and Version Your Model")

uploaded_new_data = st.file_uploader(
    "ğŸ“ Upload new dataset to retrain the model (CSV or Excel)", type=["csv", "xlsx"]
)

if uploaded_new_data:
    if uploaded_new_data.name.endswith(".csv"):
        df_new = pd.read_csv(uploaded_new_data)
    else:
        df_new = pd.read_excel(uploaded_new_data)

    st.write("âœ… Uploaded New Dataset Preview:")
    st.dataframe(df_new.head())

    target_col = "exoplanet_archive_disposition"

    if target_col not in df_new.columns:
        st.error(f"âŒ Target column '{target_col}' not found!")
    else:
        if st.button("ğŸš€ Retrain Model"):
            with st.spinner("Training new model... please wait â³"):
                X = df_new.drop(columns=[target_col])
                y = df_new[target_col]

                X = X.select_dtypes(include=["float64", "int64"]).fillna(X.median())
                le_new = LabelEncoder()
                y_encoded = le_new.fit_transform(y)
                scaler_new = StandardScaler()
                X_scaled = scaler_new.fit_transform(X)

                X_train, X_test, y_train, y_test = train_test_split(
                    X_scaled, y_encoded, test_size=0.2, random_state=42
                )

                model_new = DecisionTreeClassifier(
                    criterion="gini",
                    max_depth=10,
                    min_samples_split=5,
                    random_state=42
                )
                model_new.fit(X_train, y_train)
                y_pred = model_new.predict(X_test)

                acc_new = accuracy_score(y_test, y_pred)
                st.success(f"âœ… New Model Accuracy: **{acc_new:.4f}**")

                current_version = metadata["current_version"]
                prev_acc = metadata["versions"].get(str(current_version), {}).get("accuracy")

                if prev_acc:
                    st.info(f"ğŸ“Š Current Model (v{current_version}) Accuracy: {prev_acc:.4f}")
                    if acc_new > prev_acc:
                        st.success("ğŸš€ The new model performs better!")
                    else:
                        st.warning("âš ï¸ The new model performs worse than the current version.")

                report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()
                st.subheader("ğŸ“ˆ Evaluation Metrics")
                st.dataframe(report_df)

                importances = pd.Series(model_new.feature_importances_, index=X.columns).sort_values(ascending=False)
                plt.figure(figsize=(7, 4))
                sns.barplot(x=importances.head(10), y=importances.head(10).index)
                plt.title("Top 10 Feature Importances (New Model)")
                plt.tight_layout()
                plt.savefig("../models/feature_importances_new.png")
                st.image("../models/feature_importances_new.png", width=450)

                if st.button("ğŸ’¾ Upgrade to New Model Version"):
                    new_version = current_version + 1
                    joblib.dump(model_new, f"../models/trained_model_v{new_version}.pkl")
                    joblib.dump(scaler_new, f"../models/scaler_v{new_version}.pkl")
                    joblib.dump(le_new, f"../models/label_encoder_v{new_version}.pkl")

                    metadata["current_version"] = new_version
                    metadata["versions"][str(new_version)] = {
                        "accuracy": float(acc_new),
                        "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    }

                    with open(metadata_path, "w") as f:
                        json.dump(metadata, f, indent=4)

                    st.success(f"ğŸ‰ Model upgraded to version {new_version} successfully!")

st.write("For detailed information about each feature, please check this link:")

st.markdown(
    """
    <a href="https://exoplanetarchive.ipac.caltech.edu/docs/API_kepcandidate_columns.html#pdisposition" target="_blank">
        <button style="padding:10px; font-size:16px;">Open Exoplanet Archive</button>
    </a>
    """,
    unsafe_allow_html=True
)


